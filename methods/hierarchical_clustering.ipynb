{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn import metrics\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read every cohort study file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [pd.read_csv(file, index_col=0, low_memory=False) for file in sorted(glob.glob('../cohort_studies_full_data/' + \"/*.\"+'csv'))]\n",
    "cohorts = [file.split(\".\")[0] for file in sorted(os.listdir('../cohort_studies_full_data/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all cohorts as a dataframe\n",
    "cohort_studies = dict()\n",
    "# dfsss = dict()\n",
    "\n",
    "for cohort, dataset in zip(cohorts, datasets):\n",
    "    cohort_n = cohort.split(\"_MERGE\")[0]\n",
    "    cohort_studies[cohort_n] = dataset.loc[dataset['Months']==0].copy() # reduce to BL visit\n",
    "#     dfsss[cohort_n] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_sub = [pd.read_csv(file, index_col=0, low_memory=False) for file in sorted(glob.glob('../preprocessed_datasets/' + \"/*.\"+'csv'))]\n",
    "cohorts_sub = [file.split(\".\")[0] for file in sorted(os.listdir('../preprocessed_datasets/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all cohorts as a dataframe\n",
    "cohort_studies_sub = dict()\n",
    "\n",
    "for cohort, dataset in zip(cohorts_sub, datasets_sub):\n",
    "    cohort_studies_sub[cohort] = dataset.loc[dataset['Months']==0].copy() # reduce to BL visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the preprocessed columns from sub table of each dataset to the main table of dataset\n",
    "for i in cohort_studies:\n",
    "#     cols = cohort_studies_sub[i].columns.difference(cohort_studies[i].columns)\n",
    "    cols = ['Age', 'Sex', 'Education', 'APOE4', 'CDR', 'Race']\n",
    "    \n",
    "    for col in cols:\n",
    "        \n",
    "        if col in cohort_studies_sub[i].columns:\n",
    "            cohort_studies[i][col] = cohort_studies_sub[i][col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read harmonized mapping tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality = [pd.read_csv(file, sep=',') for file in sorted(glob.glob('../feature_tables' + \"/*.\"+'csv'))]\n",
    "name = [file.split(\".\")[0] for file in sorted(os.listdir('../feature_tables'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all modalities as a dataframe\n",
    "mappings = dict()\n",
    "\n",
    "for moda, na in zip(modality, name):\n",
    "    mappings[na.split(' - ')[1]] = moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonized_features = pd.concat(mappings, ignore_index=True) # combine all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude categorical and taboo features\n",
    "harmonized_features = harmonized_features.loc[(harmonized_features['Rank']!=1) & (harmonized_features['Rank']!=2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the feature availability files for all cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_mapp = [pd.read_csv(file, sep='\\t') for file in sorted(glob.glob('../feature_availability_in_cohorts' + \"/*.\"+'tsv'))]\n",
    "tablesss = [file.split(\".\")[0] for file in sorted(os.listdir('../feature_availability_in_cohorts'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all modalities as a dataframe\n",
    "available_features = dict()\n",
    "\n",
    "for modal, df in zip(tablesss, ava_mapp):\n",
    "    available_features[modal] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_features = pd.concat(available_features, ignore_index=True) # combine all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_features.replace({0: np.nan}, inplace=True) # 0 indicates that the feature was not measured "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read cutoffs obtained using all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_method = [pd.read_csv(file, index_col=0, low_memory=False) for file in sorted(glob.glob('../results/cutoffs/' + \"/*.\"+'csv'))]\n",
    "method_name = [file.split(\".\")[0] for file in sorted(os.listdir('../results/cutoffs/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains each cutoff table as a dataframe\n",
    "cutoffs_ = dict()\n",
    "\n",
    "for tm, mn in zip(table_method, method_name):\n",
    "    cutoffs_[mn] = tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cutoffs_['km_cutoffs'].rename(columns={col: col.split('_')[0]}, inplace=True) for col in cutoffs_['km_cutoffs'].columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecetion of cohort studies for A/T/N assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the patient that have CSF biomarker, disregard the diagnostic status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "atn = pd.DataFrame(index=available_features['csf'].iloc[:3].replace({0: np.nan}).dropna(axis=1).columns[1:].to_list(), columns=mappings['csf'].Feature.loc[0:2].to_list()+([\"Total\"]))\n",
    "# atn = pd.DataFrame(index=cohort_studies, columns=['A', 'T', 'N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in atn.index:\n",
    "    for feat in mappings['csf'][cohort].loc[0:2].dropna().to_list():\n",
    "        if feat in cohort_studies[cohort].columns:\n",
    "            atn.loc[cohort, mappings['csf'].loc[mappings['csf'][cohort]==feat, 'Feature']] = len(cohort_studies[cohort][feat].dropna())\n",
    "            atn.loc[cohort, 'Total'] = len(cohort_studies[cohort][mappings['csf'][cohort].loc[0:2].dropna().to_list()].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = pd.DataFrame(index=available_features['csf'].iloc[:3].replace({0: np.nan}).dropna(axis=1).columns[1:].to_list(), columns=cohort_studies['ADNI']['Diagnosis'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in diag.index:\n",
    "    for dia in diag.columns:\n",
    "        diag.loc[cohort, dia] = len(cohort_studies[cohort].loc[cohort_studies[cohort]['Diagnosis']==dia][mappings['csf'][cohort].loc[0:2].dropna().to_list()].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the empty columns from all cohorts that we are intrested in\n",
    "### Remove the participant without all 3 CSF biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cohorts = dict()\n",
    "\n",
    "for coh in diag.index:\n",
    "    selected_cohorts[coh] = cohort_studies[coh].dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_feats = dict()\n",
    "\n",
    "# existing_features.set_index('Feature', inplace=True)\n",
    "\n",
    "for feat in existing_features.Feature:\n",
    "    total_feats[feat] = existing_features.loc[existing_features.Feature==feat][selected_cohorts].dropna(axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in atn.index:\n",
    "    feat = mappings['csf'][cohort].loc[0:2].dropna().to_list()\n",
    "    cohort_studies[cohort] = cohort_studies[cohort].dropna(subset=feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Some features have suffix due to merging tables for certain cohorts, first investigate if all the harmonized features are in cohorts. Rename the ones that have suffix so it can be compatible to work with our harmonized names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_studies['ADNI'] = cohort_studies['ADNI'].rename(columns={'PTEDUCAT_x': 'PTEDUCAT', 'TRABSCOR_bl': 'TRABSCOR', 'LDELTOTAL_BL': 'LDELTOTAL'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSF biomarkers, two classes, normal vs abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modality_ = ['clinical_i', 'clinical_ii','hippocampus', 'csf']\n",
    "# modality_ = ['basal_ganglia', 'brain_poles_volume', 'cerebellum', 'clinical_i', \n",
    "#             'clinical_ii', 'csf', 'diencephalus', 'general_brain', \n",
    "#             'mri_others', 'pet', 'plasma', 'ventricles', 'hippocampus']\n",
    "modality_ = ['basal_ganglia', 'brain_poles_volume', 'cerebellum', 'csf', 'diencephalus', 'general_brain', \n",
    "            'mri_others', 'pet', 'plasma', 'ventricles', 'hippocampus']\n",
    "\n",
    "selected_feat = dict()\n",
    "\n",
    "for i in modality_:\n",
    "    selected_feat[i] = mappings[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe containing all the mapped features\n",
    "features_all = pd.concat(selected_feat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = features_all[atn.index.union(['Feature', 'Rank'])] # subset the cohorts of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the features that are not available in all studies\n",
    "features_all = features_all.loc[features_all['Feature'].isin(existing_features[atn.index.union(['Feature'])].dropna(how='all')['Feature'].to_list())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert MRI measurements to mm3, same as ADNI and other cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_nacc = ['basal_ganglia', 'brain_poles_volume', 'cerebellum', 'diencephalus', 'general_brain', \n",
    "            'mri_others', 'pet', 'plasma', 'ventricles', 'hippocampus']\n",
    "\n",
    "for i in mri_nacc:\n",
    "    \n",
    "    for variable in mappings[i][['Feature', 'NACC']].dropna()['Feature'].to_list():\n",
    "        \n",
    "        if \"Volume\" in variable:\n",
    "            nacc_var = mappings[i].loc[mappings[i]['Feature']==variable, 'NACC']\n",
    "            cohort_studies['NACC'][nacc_var] = cohort_studies['NACC'][nacc_var] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "nacc_mri_to_convert = list()\n",
    "\n",
    "for i in mri_nacc:\n",
    "    \n",
    "    for feat_ in mappings[i]['NACC'].dropna().to_list():\n",
    "        nacc_mri_to_convert.append(feat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort_studies['NACC'][nacc_mri_to_convert].dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rank 1 --> Categorical features\n",
    "* Rank 2 --> Taboo features: some categorical and some numerical\n",
    "* Rank nan --> Numerical features \n",
    "\n",
    "replace nan with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all['Rank'].replace({np.nan: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all.replace({\"No total score.\": np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix PharmaCog column names\n",
    "for i in cohort_studies['PharmaCog'].columns:\n",
    "    if \"\\xa0\" in i:\n",
    "        new = str(i).replace(u'\\xa0', u'')\n",
    "        cohort_studies['PharmaCog'].rename(columns={i: new}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'MCI': 145})"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(cohort_studies['PharmaCog']['Diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_atn_participants(dfss, cohorts, thresholds, features):\n",
    "    \"\"\"cohorts: list of cohort names \n",
    "       dfss: dictionary of cohorts where each key is the name of a cohort\n",
    "       thresholds: cutoff values obtained using a methodology\n",
    "       \n",
    "       Select the features and participants and categorize the participant into ATN profiles using thresholds\n",
    "       obtained from each methodology.\n",
    "       \n",
    "       return a df which contain the combination of paticipant from the selected cohorts while harmonizing\n",
    "       the features names.\n",
    "    \"\"\"\n",
    "    \n",
    "    # make a list of additional features to be investigated \n",
    "#     additional_feat = ['Age', 'Sex', 'Education', 'APOE4', 'CDR', 'Race']\n",
    "    additional_feat = ['APOE4']\n",
    "\n",
    "    # make an empty dictionary to add the datasets to\n",
    "    df_= pd.DataFrame(columns=set(features.loc[features['Rank']==0]\n",
    "                                  [cohorts + ['Feature']].dropna()['Feature']).difference(['Feature'] + list(thresholds.columns)).union(additional_feat))\n",
    "   \n",
    "    for i in cohorts:\n",
    "#         print(i)\n",
    "\n",
    "        dfs = dict()\n",
    "        dfs[i] = dfss[i].copy() # make a copy of the dataset of interest\n",
    "        # select the subset of datasets with features to be investigated\n",
    "        dfs[i] = dfs[i][features.loc[features['Rank']==0][cohorts + ['Feature']].dropna()[i].to_list() + additional_feat].dropna(axis=1, how='all')\n",
    "        # rename all the columns so we can concat the datasets later\n",
    "        [dfs[i].rename(columns={col: coln}, inplace=True) for col, coln in \n",
    "         zip(features.loc[features['Rank']==0][cohorts + ['Feature']].dropna()[i].to_list(), \n",
    "             features.loc[features['Rank']==0][cohorts + ['Feature']].dropna()['Feature'].to_list())]\n",
    "        dfs[i]['Cohort'] = i # add a cohort name column\n",
    "        # change the datatype to str as these are categorical features. astype doesn't work as it will include nan values\n",
    "        dfs[i] = dfs[i].replace({'APOE4': {0.0: '0', 2.0: '2', 1.0: '1'}}) \n",
    "\n",
    "        if i!='NACC':\n",
    "            \n",
    "            for biomarker in thresholds.columns:\n",
    "                # select the cutoff value for each biomarker for each cohort\n",
    "                threshold = thresholds.loc[i][biomarker]\n",
    "\n",
    "                # dichotomize the participants\n",
    "                if biomarker == 'pTau in CSF': \n",
    "                    dfs[i].loc[dfs[i][biomarker]>threshold, \"T\"] = 'T+'\n",
    "                    dfs[i].loc[dfs[i][biomarker]<threshold, \"T\"] = 'T-'\n",
    "\n",
    "                elif biomarker == 'tTau in CSF': \n",
    "                    dfs[i].loc[dfs[i][biomarker]>threshold, \"N\"] = 'N+'\n",
    "                    dfs[i].loc[dfs[i][biomarker]<threshold, \"N\"] = 'N-'\n",
    "\n",
    "                else: \n",
    "                    dfs[i].loc[dfs[i][biomarker]<threshold, \"A\"] = 'A+'\n",
    "                    dfs[i].loc[dfs[i][biomarker]>threshold, \"A\"] = 'A-'\n",
    "\n",
    "            # join the 3 columns to make the final ATN categorie                                 \n",
    "            dfs[i]['ATN'] = dfs[i]['A'] + dfs[i]['T'] + dfs[i]['N']\n",
    "            # remove the columns that we are not interested in\n",
    "            dfs[i] = dfs[i][dfs[i].columns.difference(['A', 'T', 'N', 'Mini-Mental State Examination (MMSE)'] + list(thresholds.columns))]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            elisa_index = cohort_studies[i].loc[(cohort_studies[i]['CSFTTMD']==1)].index\n",
    "            xmap_index = cohort_studies[i].loc[(cohort_studies[i]['CSFTTMD']==2)].index\n",
    "            \n",
    "            for biomarker in thresholds.columns:\n",
    "                # select the cutoff value for each biomarker for each cohort\n",
    "                elisa = thresholds.loc[i + \"_ELISA\"][biomarker] # ELISA\n",
    "                xmap = thresholds.loc[i + \"_XMAP\"][biomarker] #XMAP\n",
    "\n",
    "                # dichotomize the participants\n",
    "                if biomarker == 'pTau in CSF': \n",
    "                    \n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]>elisa), \"T\"] = 'T+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]<elisa), \"T\"] = 'T-'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]>xmap), \"T\"] = 'T+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]<xmap), \"T\"] = 'T-'\n",
    "\n",
    "                elif biomarker == 'tTau in CSF': \n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]>elisa), \"N\"] = 'N+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]<elisa), \"N\"] = 'N-'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]>xmap), \"N\"] = 'N+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]<xmap), \"N\"] = 'N-'\n",
    "\n",
    "                else: \n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]<elisa), \"A\"] = 'A+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]>elisa), \"A\"] = 'A-'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]<xmap), \"A\"] = 'A+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]>xmap), \"A\"] = 'A-'\n",
    "\n",
    "            # join the 3 columns to make the final ATN categorie                                 \n",
    "            dfs[i]['ATN'] = dfs[i]['A'] + dfs[i]['T'] + dfs[i]['N']\n",
    "            # remove the columns that we are not interested in\n",
    "            dfs[i] = dfs[i][dfs[i].columns.difference(['A', 'T', 'N', 'Mini-Mental State Examination (MMSE)', 'Trail Making Test (TMT) A', 'Verbal fluency tests (Semantic) Animal'] + list(thresholds.columns))]\n",
    "            \n",
    "#         print(dfs[i])\n",
    "\n",
    "        \n",
    "        df_ = pd.concat([df_, dfs[i]])\n",
    "#         print(df_)\n",
    "#         df_ = df_.dropna(axis=1, thresh=len(df_.index)/2)\n",
    "#         print(df_)\n",
    "    \n",
    "    df_ = df_.dropna(axis=1, how='all')\n",
    "    df_ = df_.dropna(axis=1, thresh=1200)\n",
    "\n",
    "    df_ = df_.dropna()\n",
    "\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_df_km = select_atn_participants(cohort_studies, ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog'], cutoffs_['km_cutoffs'], features_all)\n",
    "clustering_df_gmm = select_atn_participants(cohort_studies, ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog'], cutoffs_['gmm_cutoffs'], features_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Right Lateralorbitofrontal Mean Cortical Thickness</th>\n",
       "      <th>Right Parahippocampal Mean Cortical Thickness</th>\n",
       "      <th>Right Rostral Middle Frontal Mean Cortical Thickness</th>\n",
       "      <th>Left Paracentral Gray Matter Volume</th>\n",
       "      <th>Right Transverse Temporal Grey Matter Volume</th>\n",
       "      <th>Left Pars Opercularis Mean Cortical Thickness</th>\n",
       "      <th>Left Posterior Cingulate Mean Cortical Thickness</th>\n",
       "      <th>Left Lateraloccipital Mean Cortical Thickness</th>\n",
       "      <th>Left Transverse Temporal Grey Matter Volume</th>\n",
       "      <th>Left Transverse Temporal Mean Cortical Thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>Left Cuneus Mean Cortical Thickness</th>\n",
       "      <th>Right Superiorfrontal Mean Cortical Thickness</th>\n",
       "      <th>Left Superior Parietal Gray Matter Volume</th>\n",
       "      <th>Right Isthmus Cingulate Mean Cortical Thickness</th>\n",
       "      <th>Left Pericalcarine Mean Cortical Thickness</th>\n",
       "      <th>Right Pericalcarine Mean Cortical Thickness</th>\n",
       "      <th>Right Superior Temporal Mean Cortical Thickness</th>\n",
       "      <th>Right Lateraloccipital Mean Cortical Thickness</th>\n",
       "      <th>ATN</th>\n",
       "      <th>Cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>2.551</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.121</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>1039.0</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.713</td>\n",
       "      <td>2.379</td>\n",
       "      <td>1312.0</td>\n",
       "      <td>2.221</td>\n",
       "      <td>...</td>\n",
       "      <td>1.933</td>\n",
       "      <td>2.576</td>\n",
       "      <td>12473.0</td>\n",
       "      <td>2.459</td>\n",
       "      <td>1.595</td>\n",
       "      <td>1.482</td>\n",
       "      <td>2.769</td>\n",
       "      <td>2.452</td>\n",
       "      <td>A-T-N-</td>\n",
       "      <td>ADNI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>2.463</td>\n",
       "      <td>3.077</td>\n",
       "      <td>2.205</td>\n",
       "      <td>2784.0</td>\n",
       "      <td>768.0</td>\n",
       "      <td>2.446</td>\n",
       "      <td>2.488</td>\n",
       "      <td>2.223</td>\n",
       "      <td>1062.0</td>\n",
       "      <td>2.131</td>\n",
       "      <td>...</td>\n",
       "      <td>1.644</td>\n",
       "      <td>2.566</td>\n",
       "      <td>13904.0</td>\n",
       "      <td>2.438</td>\n",
       "      <td>1.360</td>\n",
       "      <td>1.411</td>\n",
       "      <td>2.648</td>\n",
       "      <td>2.157</td>\n",
       "      <td>A+T-N-</td>\n",
       "      <td>ADNI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>2.445</td>\n",
       "      <td>2.507</td>\n",
       "      <td>1.971</td>\n",
       "      <td>2355.0</td>\n",
       "      <td>571.0</td>\n",
       "      <td>2.219</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.008</td>\n",
       "      <td>827.0</td>\n",
       "      <td>1.992</td>\n",
       "      <td>...</td>\n",
       "      <td>1.734</td>\n",
       "      <td>2.168</td>\n",
       "      <td>10199.0</td>\n",
       "      <td>2.065</td>\n",
       "      <td>1.253</td>\n",
       "      <td>1.332</td>\n",
       "      <td>2.437</td>\n",
       "      <td>1.984</td>\n",
       "      <td>A-T-N-</td>\n",
       "      <td>ADNI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>2.377</td>\n",
       "      <td>3.016</td>\n",
       "      <td>2.082</td>\n",
       "      <td>2499.0</td>\n",
       "      <td>778.0</td>\n",
       "      <td>2.399</td>\n",
       "      <td>2.922</td>\n",
       "      <td>1.955</td>\n",
       "      <td>879.0</td>\n",
       "      <td>1.928</td>\n",
       "      <td>...</td>\n",
       "      <td>1.529</td>\n",
       "      <td>2.388</td>\n",
       "      <td>12750.0</td>\n",
       "      <td>2.471</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1.313</td>\n",
       "      <td>2.669</td>\n",
       "      <td>2.039</td>\n",
       "      <td>A-T-N-</td>\n",
       "      <td>ADNI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>2.428</td>\n",
       "      <td>2.637</td>\n",
       "      <td>2.388</td>\n",
       "      <td>3372.0</td>\n",
       "      <td>621.0</td>\n",
       "      <td>2.585</td>\n",
       "      <td>2.230</td>\n",
       "      <td>1.973</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>2.282</td>\n",
       "      <td>...</td>\n",
       "      <td>1.813</td>\n",
       "      <td>2.612</td>\n",
       "      <td>12343.0</td>\n",
       "      <td>2.022</td>\n",
       "      <td>1.543</td>\n",
       "      <td>1.660</td>\n",
       "      <td>2.671</td>\n",
       "      <td>2.031</td>\n",
       "      <td>A+T-N-</td>\n",
       "      <td>ADNI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-37-024</th>\n",
       "      <td>2.470</td>\n",
       "      <td>2.160</td>\n",
       "      <td>2.280</td>\n",
       "      <td>1469.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>1.680</td>\n",
       "      <td>1.890</td>\n",
       "      <td>1.900</td>\n",
       "      <td>551.0</td>\n",
       "      <td>1.540</td>\n",
       "      <td>...</td>\n",
       "      <td>1.480</td>\n",
       "      <td>2.440</td>\n",
       "      <td>6353.0</td>\n",
       "      <td>1.810</td>\n",
       "      <td>1.220</td>\n",
       "      <td>1.310</td>\n",
       "      <td>2.340</td>\n",
       "      <td>1.800</td>\n",
       "      <td>A+T-N-</td>\n",
       "      <td>PharmaCog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-37-025</th>\n",
       "      <td>2.170</td>\n",
       "      <td>2.020</td>\n",
       "      <td>1.860</td>\n",
       "      <td>2476.0</td>\n",
       "      <td>611.0</td>\n",
       "      <td>2.140</td>\n",
       "      <td>2.010</td>\n",
       "      <td>1.920</td>\n",
       "      <td>914.0</td>\n",
       "      <td>2.010</td>\n",
       "      <td>...</td>\n",
       "      <td>1.540</td>\n",
       "      <td>2.090</td>\n",
       "      <td>9683.0</td>\n",
       "      <td>1.770</td>\n",
       "      <td>1.360</td>\n",
       "      <td>1.210</td>\n",
       "      <td>2.220</td>\n",
       "      <td>1.990</td>\n",
       "      <td>A-T-N-</td>\n",
       "      <td>PharmaCog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-37-026</th>\n",
       "      <td>2.540</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.250</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>814.0</td>\n",
       "      <td>2.360</td>\n",
       "      <td>2.540</td>\n",
       "      <td>1.990</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>2.510</td>\n",
       "      <td>...</td>\n",
       "      <td>1.580</td>\n",
       "      <td>2.540</td>\n",
       "      <td>11016.0</td>\n",
       "      <td>2.300</td>\n",
       "      <td>1.470</td>\n",
       "      <td>1.580</td>\n",
       "      <td>2.790</td>\n",
       "      <td>2.090</td>\n",
       "      <td>A+T+N+</td>\n",
       "      <td>PharmaCog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-37-027</th>\n",
       "      <td>2.540</td>\n",
       "      <td>2.580</td>\n",
       "      <td>2.180</td>\n",
       "      <td>3467.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>2.300</td>\n",
       "      <td>2.430</td>\n",
       "      <td>2.060</td>\n",
       "      <td>794.0</td>\n",
       "      <td>1.600</td>\n",
       "      <td>...</td>\n",
       "      <td>1.740</td>\n",
       "      <td>2.390</td>\n",
       "      <td>11785.0</td>\n",
       "      <td>2.550</td>\n",
       "      <td>1.480</td>\n",
       "      <td>1.500</td>\n",
       "      <td>2.710</td>\n",
       "      <td>2.130</td>\n",
       "      <td>A+T-N-</td>\n",
       "      <td>PharmaCog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-37-028</th>\n",
       "      <td>2.330</td>\n",
       "      <td>2.660</td>\n",
       "      <td>2.140</td>\n",
       "      <td>3185.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>2.460</td>\n",
       "      <td>2.600</td>\n",
       "      <td>1.950</td>\n",
       "      <td>1143.0</td>\n",
       "      <td>2.400</td>\n",
       "      <td>...</td>\n",
       "      <td>1.560</td>\n",
       "      <td>2.470</td>\n",
       "      <td>9968.0</td>\n",
       "      <td>2.210</td>\n",
       "      <td>1.580</td>\n",
       "      <td>1.540</td>\n",
       "      <td>2.630</td>\n",
       "      <td>2.050</td>\n",
       "      <td>A+T-N-</td>\n",
       "      <td>PharmaCog</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1332 rows Ã— 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Right Lateralorbitofrontal Mean Cortical Thickness  \\\n",
       "2002                                                   2.551    \n",
       "2022                                                   2.463    \n",
       "2026                                                   2.445    \n",
       "2031                                                   2.377    \n",
       "2042                                                   2.428    \n",
       "...                                                      ...    \n",
       "PT-37-024                                              2.470    \n",
       "PT-37-025                                              2.170    \n",
       "PT-37-026                                              2.540    \n",
       "PT-37-027                                              2.540    \n",
       "PT-37-028                                              2.330    \n",
       "\n",
       "           Right Parahippocampal Mean Cortical Thickness  \\\n",
       "2002                                               2.495   \n",
       "2022                                               3.077   \n",
       "2026                                               2.507   \n",
       "2031                                               3.016   \n",
       "2042                                               2.637   \n",
       "...                                                  ...   \n",
       "PT-37-024                                          2.160   \n",
       "PT-37-025                                          2.020   \n",
       "PT-37-026                                          2.250   \n",
       "PT-37-027                                          2.580   \n",
       "PT-37-028                                          2.660   \n",
       "\n",
       "           Right Rostral Middle Frontal Mean Cortical Thickness  \\\n",
       "2002                                                   2.121      \n",
       "2022                                                   2.205      \n",
       "2026                                                   1.971      \n",
       "2031                                                   2.082      \n",
       "2042                                                   2.388      \n",
       "...                                                      ...      \n",
       "PT-37-024                                              2.280      \n",
       "PT-37-025                                              1.860      \n",
       "PT-37-026                                              2.250      \n",
       "PT-37-027                                              2.180      \n",
       "PT-37-028                                              2.140      \n",
       "\n",
       "           Left Paracentral Gray Matter Volume  \\\n",
       "2002                                    2940.0   \n",
       "2022                                    2784.0   \n",
       "2026                                    2355.0   \n",
       "2031                                    2499.0   \n",
       "2042                                    3372.0   \n",
       "...                                        ...   \n",
       "PT-37-024                               1469.0   \n",
       "PT-37-025                               2476.0   \n",
       "PT-37-026                               3120.0   \n",
       "PT-37-027                               3467.0   \n",
       "PT-37-028                               3185.0   \n",
       "\n",
       "           Right Transverse Temporal Grey Matter Volume  \\\n",
       "2002                                             1039.0   \n",
       "2022                                              768.0   \n",
       "2026                                              571.0   \n",
       "2031                                              778.0   \n",
       "2042                                              621.0   \n",
       "...                                                 ...   \n",
       "PT-37-024                                         506.0   \n",
       "PT-37-025                                         611.0   \n",
       "PT-37-026                                         814.0   \n",
       "PT-37-027                                         797.0   \n",
       "PT-37-028                                         614.0   \n",
       "\n",
       "           Left Pars Opercularis Mean Cortical Thickness  \\\n",
       "2002                                               2.516   \n",
       "2022                                               2.446   \n",
       "2026                                               2.219   \n",
       "2031                                               2.399   \n",
       "2042                                               2.585   \n",
       "...                                                  ...   \n",
       "PT-37-024                                          1.680   \n",
       "PT-37-025                                          2.140   \n",
       "PT-37-026                                          2.360   \n",
       "PT-37-027                                          2.300   \n",
       "PT-37-028                                          2.460   \n",
       "\n",
       "           Left Posterior Cingulate Mean Cortical Thickness  \\\n",
       "2002                                                  2.713   \n",
       "2022                                                  2.488   \n",
       "2026                                                  2.129   \n",
       "2031                                                  2.922   \n",
       "2042                                                  2.230   \n",
       "...                                                     ...   \n",
       "PT-37-024                                             1.890   \n",
       "PT-37-025                                             2.010   \n",
       "PT-37-026                                             2.540   \n",
       "PT-37-027                                             2.430   \n",
       "PT-37-028                                             2.600   \n",
       "\n",
       "           Left Lateraloccipital Mean Cortical Thickness  \\\n",
       "2002                                               2.379   \n",
       "2022                                               2.223   \n",
       "2026                                               2.008   \n",
       "2031                                               1.955   \n",
       "2042                                               1.973   \n",
       "...                                                  ...   \n",
       "PT-37-024                                          1.900   \n",
       "PT-37-025                                          1.920   \n",
       "PT-37-026                                          1.990   \n",
       "PT-37-027                                          2.060   \n",
       "PT-37-028                                          1.950   \n",
       "\n",
       "           Left Transverse Temporal Grey Matter Volume  \\\n",
       "2002                                            1312.0   \n",
       "2022                                            1062.0   \n",
       "2026                                             827.0   \n",
       "2031                                             879.0   \n",
       "2042                                            1399.0   \n",
       "...                                                ...   \n",
       "PT-37-024                                        551.0   \n",
       "PT-37-025                                        914.0   \n",
       "PT-37-026                                       1037.0   \n",
       "PT-37-027                                        794.0   \n",
       "PT-37-028                                       1143.0   \n",
       "\n",
       "           Left Transverse Temporal Mean Cortical Thickness  ...  \\\n",
       "2002                                                  2.221  ...   \n",
       "2022                                                  2.131  ...   \n",
       "2026                                                  1.992  ...   \n",
       "2031                                                  1.928  ...   \n",
       "2042                                                  2.282  ...   \n",
       "...                                                     ...  ...   \n",
       "PT-37-024                                             1.540  ...   \n",
       "PT-37-025                                             2.010  ...   \n",
       "PT-37-026                                             2.510  ...   \n",
       "PT-37-027                                             1.600  ...   \n",
       "PT-37-028                                             2.400  ...   \n",
       "\n",
       "           Left Cuneus Mean Cortical Thickness  \\\n",
       "2002                                     1.933   \n",
       "2022                                     1.644   \n",
       "2026                                     1.734   \n",
       "2031                                     1.529   \n",
       "2042                                     1.813   \n",
       "...                                        ...   \n",
       "PT-37-024                                1.480   \n",
       "PT-37-025                                1.540   \n",
       "PT-37-026                                1.580   \n",
       "PT-37-027                                1.740   \n",
       "PT-37-028                                1.560   \n",
       "\n",
       "           Right Superiorfrontal Mean Cortical Thickness  \\\n",
       "2002                                               2.576   \n",
       "2022                                               2.566   \n",
       "2026                                               2.168   \n",
       "2031                                               2.388   \n",
       "2042                                               2.612   \n",
       "...                                                  ...   \n",
       "PT-37-024                                          2.440   \n",
       "PT-37-025                                          2.090   \n",
       "PT-37-026                                          2.540   \n",
       "PT-37-027                                          2.390   \n",
       "PT-37-028                                          2.470   \n",
       "\n",
       "           Left Superior Parietal Gray Matter Volume  \\\n",
       "2002                                         12473.0   \n",
       "2022                                         13904.0   \n",
       "2026                                         10199.0   \n",
       "2031                                         12750.0   \n",
       "2042                                         12343.0   \n",
       "...                                              ...   \n",
       "PT-37-024                                     6353.0   \n",
       "PT-37-025                                     9683.0   \n",
       "PT-37-026                                    11016.0   \n",
       "PT-37-027                                    11785.0   \n",
       "PT-37-028                                     9968.0   \n",
       "\n",
       "           Right Isthmus Cingulate Mean Cortical Thickness  \\\n",
       "2002                                                 2.459   \n",
       "2022                                                 2.438   \n",
       "2026                                                 2.065   \n",
       "2031                                                 2.471   \n",
       "2042                                                 2.022   \n",
       "...                                                    ...   \n",
       "PT-37-024                                            1.810   \n",
       "PT-37-025                                            1.770   \n",
       "PT-37-026                                            2.300   \n",
       "PT-37-027                                            2.550   \n",
       "PT-37-028                                            2.210   \n",
       "\n",
       "           Left Pericalcarine Mean Cortical Thickness  \\\n",
       "2002                                            1.595   \n",
       "2022                                            1.360   \n",
       "2026                                            1.253   \n",
       "2031                                            1.335   \n",
       "2042                                            1.543   \n",
       "...                                               ...   \n",
       "PT-37-024                                       1.220   \n",
       "PT-37-025                                       1.360   \n",
       "PT-37-026                                       1.470   \n",
       "PT-37-027                                       1.480   \n",
       "PT-37-028                                       1.580   \n",
       "\n",
       "           Right Pericalcarine Mean Cortical Thickness  \\\n",
       "2002                                             1.482   \n",
       "2022                                             1.411   \n",
       "2026                                             1.332   \n",
       "2031                                             1.313   \n",
       "2042                                             1.660   \n",
       "...                                                ...   \n",
       "PT-37-024                                        1.310   \n",
       "PT-37-025                                        1.210   \n",
       "PT-37-026                                        1.580   \n",
       "PT-37-027                                        1.500   \n",
       "PT-37-028                                        1.540   \n",
       "\n",
       "           Right Superior Temporal Mean Cortical Thickness  \\\n",
       "2002                                                 2.769   \n",
       "2022                                                 2.648   \n",
       "2026                                                 2.437   \n",
       "2031                                                 2.669   \n",
       "2042                                                 2.671   \n",
       "...                                                    ...   \n",
       "PT-37-024                                            2.340   \n",
       "PT-37-025                                            2.220   \n",
       "PT-37-026                                            2.790   \n",
       "PT-37-027                                            2.710   \n",
       "PT-37-028                                            2.630   \n",
       "\n",
       "           Right Lateraloccipital Mean Cortical Thickness     ATN     Cohort  \n",
       "2002                                                2.452  A-T-N-       ADNI  \n",
       "2022                                                2.157  A+T-N-       ADNI  \n",
       "2026                                                1.984  A-T-N-       ADNI  \n",
       "2031                                                2.039  A-T-N-       ADNI  \n",
       "2042                                                2.031  A+T-N-       ADNI  \n",
       "...                                                   ...     ...        ...  \n",
       "PT-37-024                                           1.800  A+T-N-  PharmaCog  \n",
       "PT-37-025                                           1.990  A-T-N-  PharmaCog  \n",
       "PT-37-026                                           2.090  A+T+N+  PharmaCog  \n",
       "PT-37-027                                           2.130  A+T-N-  PharmaCog  \n",
       "PT-37-028                                           2.050  A+T-N-  PharmaCog  \n",
       "\n",
       "[1332 rows x 108 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_df_km"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exclude CSF Volume as it seems wrong in the NACC dataset and that could potentially add bias to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_df_km = clustering_df_km[clustering_df_km.columns.difference(['Cerebrospinal Fluid Volume'])]\n",
    "clustering_df_gmm = clustering_df_gmm[clustering_df_gmm.columns.difference(['Cerebrospinal Fluid Volume'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atn_based_df(df):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    labels_atn = dict()\n",
    "    score_atn = dict()\n",
    "    \n",
    "    # change the cohort names to int and write in a column\n",
    "    for i, j in zip(df.Cohort.unique(), range(len(df.Cohort.unique()))):\n",
    "        df.loc[df['Cohort']==i, 'Cohort_number'] = j\n",
    "    \n",
    "    # select the profiles that have over 20 participants\n",
    "    # make a dictionary where the selcted ATN profiles are key and \n",
    "    # the subset of dataframe categorized in that ATN profile is value\n",
    "    dfs_sub = {atn: df.loc[df.ATN==atn].copy() for atn in list((a) for a,b in dict(Counter(df.ATN)).items() if b >20)}\n",
    "    \n",
    "    for i in dfs_sub:\n",
    "#         print(i, len(dfs_sub[i].Cohort.unique()))\n",
    "        hierarchical_cluster = AgglomerativeClustering(n_clusters=len(dfs_sub[i].Cohort.unique()), affinity='euclidean', linkage='ward')\n",
    "        labels = hierarchical_cluster.fit_predict(dfs_sub[i][dfs_sub[i].columns.difference(['ATN', 'Cohort', 'Cohort_number'])])\n",
    "        labels_atn[i] = labels\n",
    "        score_atn[i] = purity_score(dfs_sub[i]['Cohort_number'], labels)\n",
    "     \n",
    "    return labels_atn, score_atn, dfs_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_km, score_km, atn_km_df = atn_based_df(clustering_df_km)\n",
    "labels_gmm, score_gmm, atn_gmm_df = atn_based_df(clustering_df_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test\n",
    "# clustering_df_km_t = clustering_df_km[clustering_df_km['Cohort']!='NACC'].copy()\n",
    "# clustering_df_gmm_t = clustering_df_gmm[clustering_df_gmm['Cohort']!='NACC'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test\n",
    "# labels_km_t, score_km_t, atn_km_df_t = atn_based_df(clustering_df_km_t)\n",
    "# labels_gmm_t, score_gmm_t, atn_gmm_df_t = atn_based_df(clustering_df_gmm_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Cluster purity (K-means):\")\n",
    "# score_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Cluster purity (GMM):\")\n",
    "# score_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels_km:\n",
    "    atn_km_df[i].loc[:, 'predicted_cohort'] = list(labels_km[i])\n",
    "\n",
    "for i_ in labels_gmm:\n",
    "    atn_gmm_df[i_].loc[:, 'predicted_cohort'] = list(labels_gmm[i_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #test\n",
    "# for i in labels_km_t:\n",
    "#     atn_km_df_t[i].loc[:, 'predicted_cohort'] = list(labels_km_t[i])\n",
    "\n",
    "# for i_ in labels_gmm_t:\n",
    "#     atn_gmm_df_t[i_].loc[:, 'predicted_cohort'] = list(labels_gmm_t[i_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cramer(dfs):\n",
    "    \"\"\" \"\"\"\n",
    "    results = dict()\n",
    "    \n",
    "    for i in dfs:\n",
    "        df_ = dfs[i].set_index('Cohort')\n",
    "        mat = pd.crosstab(df_.index, df_['predicted_cohort'])\n",
    "#         print(i, mat)\n",
    "#         print(i, round(stats.contingency.association(mat, method='cramer'), 2))\n",
    "        results[i] = round(stats.contingency.association(mat, method='cramer'), 2)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A-T-N-</th>\n",
       "      <th>A-T+N+</th>\n",
       "      <th>A-T-N+</th>\n",
       "      <th>A+T+N-</th>\n",
       "      <th>A+T-N-</th>\n",
       "      <th>A+T-N+</th>\n",
       "      <th>A+T+N+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A-T-N-  A-T+N+  A-T-N+  A+T+N-  A+T-N-  A+T-N+  A+T+N+\n",
       "0     0.2    0.31    0.52    0.32     0.3    0.38    0.28"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(calculate_cramer(atn_km_df), orient='index').transpose()[['A-T-N-', 'A-T+N+', 'A-T-N+', 'A+T+N-', 'A+T-N-', 'A+T-N+', 'A+T+N+']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A-T-N-</th>\n",
       "      <th>A-T+N+</th>\n",
       "      <th>A-T-N+</th>\n",
       "      <th>A+T+N-</th>\n",
       "      <th>A+T-N-</th>\n",
       "      <th>A+T-N+</th>\n",
       "      <th>A+T+N+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A-T-N-  A-T+N+  A-T-N+  A+T+N-  A+T-N-  A+T-N+  A+T+N+\n",
       "0    0.21    0.59    0.58    0.62    0.28    0.33    0.27"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(calculate_cramer(atn_gmm_df), orient='index').transpose()[['A-T-N-', 'A-T+N+', 'A-T-N+', 'A+T+N-', 'A+T-N-', 'A+T-N+', 'A+T+N+']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chi2(dfs):\n",
    "    \"\"\" \"\"\"\n",
    "    results_chi2 = dict()\n",
    "    results_p = dict()\n",
    "    results_df = dict()\n",
    "    results_ex = dict()\n",
    "    \n",
    "    for i in dfs:\n",
    "        df_ = dfs[i].set_index('Cohort')\n",
    "        mat = pd.crosstab(df_.index, df_['predicted_cohort'])\n",
    "        results_chi2[i], results_p[i], results_df[i], results_ex[i] = stats.chi2_contingency(mat, correction=True)\n",
    "        \n",
    "    return results_chi2, results_p, results_df, results_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_chi2_km, results_p_km, results_df_km, results_ex_km = calculate_chi2(atn_km_df)\n",
    "results_chi2_gmm, results_p_gmm, results_df_gmm, results_ex_gmm = calculate_chi2(atn_gmm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A-T-N-': 89.25610204990821, 'A+T-N-': 218.09962970174868, 'A+T+N+': 167.92391125097416, 'A-T+N+': 28.692343717790145, 'A+T+N-': 35.505407169990505, 'A-T-N+': 29.40123456790123, 'A+T-N+': 28.685219542362397}\n",
      "    \n",
      "{'A-T-N-': 2.042496476747995e-06, 'A+T-N-': 6.332504768791712e-28, 'A+T+N+': 6.1771699392248855e-19, 'A-T+N+': 0.276980979771904, 'A+T+N-': 0.49194109345408876, 'A-T-N+': 0.24749241674394443, 'A+T-N+': 0.2772883312718669}\n",
      "    \n",
      "{'A-T-N-': 36, 'A+T-N-': 36, 'A+T+N+': 36, 'A-T+N+': 25, 'A+T+N-': 36, 'A-T-N+': 25, 'A+T-N+': 25}\n"
     ]
    }
   ],
   "source": [
    "print(results_chi2_km)\n",
    "print(\"    \")\n",
    "print(results_p_km)\n",
    "print(\"    \")\n",
    "print(results_df_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A-T-N-': 2.5015117558273577e-09,\n",
       " 'A+T-N-': 3.5193231396238735e-33,\n",
       " 'A+T+N+': 2.867913391022302e-08,\n",
       " 'A-T+N+': 0.0018565188134793346,\n",
       " 'A+T+N-': 1.817626616072492e-05,\n",
       " 'A+T-N+': 0.0802408877031763,\n",
       " 'A-T-N+': 0.056990382207007244}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_p_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A-T-N- 0.0\n",
      "A-T+N+ 0.002\n",
      "A-T-N+ 0.057\n",
      "A+T+N- 0.0\n",
      "A+T-N- 0.0\n",
      "A+T-N+ 0.08\n",
      "A+T+N+ 0.0\n"
     ]
    }
   ],
   "source": [
    "for i in ['A-T-N-', 'A-T+N+', 'A-T-N+', 'A+T+N-', 'A+T-N-', 'A+T-N+', 'A+T+N+']:\n",
    "    print(i, round(results_p_gmm[i], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A-T-N-': 109.38306013989786, 'A+T-N-': 246.40864218054207, 'A+T+N+': 102.28110579852627, 'A-T+N+': 37.37500000000001, 'A+T+N-': 50.6313957535677, 'A+T-N+': 35.4576931583628, 'A-T-N+': 37.05952380952382}\n",
      "    \n",
      "{'A-T-N-': 2.5015117558273577e-09, 'A+T-N-': 3.5193231396238735e-33, 'A+T+N+': 2.867913391022302e-08, 'A-T+N+': 0.0018565188134793346, 'A+T+N-': 1.817626616072492e-05, 'A+T-N+': 0.0802408877031763, 'A-T-N+': 0.056990382207007244}\n",
      "    \n",
      "{'A-T-N-': 36, 'A+T-N-': 36, 'A+T+N+': 36, 'A-T+N+': 16, 'A+T+N-': 16, 'A+T-N+': 25, 'A-T-N+': 25}\n"
     ]
    }
   ],
   "source": [
    "print(results_chi2_gmm)\n",
    "print(\"    \")\n",
    "print(results_p_gmm)\n",
    "print(\"    \")\n",
    "print(results_df_gmm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: One could use the crosstab instead of the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_clusters(df):\n",
    "    \n",
    "    \"\"\"df: dataframe with ATN categorization using certain method and containing cluster labels\n",
    "       return: the number of participant within each cohort and within each ATN profile assigned to each labels\"\"\"\n",
    "    \n",
    "    # make an empty dictionary of dataframes to store the results\n",
    "    clustering_result_ = {i: pd.DataFrame(index=df[i].Cohort.unique(), \n",
    "                                            columns=sorted(df[i].predicted_cohort.unique())) for i in df}\n",
    "    \n",
    "    # check the number of participants clustered to each coohort within each biomarker profile\n",
    "    for profi in df:\n",
    "    \n",
    "        for name in df[profi]['Cohort'].unique():\n",
    "            clustering_result_[profi].loc[name] = Counter(df[profi].loc[df[profi]['Cohort']==name, 'predicted_cohort'])\n",
    "            \n",
    "            \n",
    "    # replace all nan enteries with 0\n",
    "    [clustering_result_[i].replace({np.nan: 0}, inplace=True) for i in clustering_result_]\n",
    "    \n",
    "    # change enteries to integer\n",
    "    for i in clustering_result_:\n",
    "        clustering_result_[i] = clustering_result_[i].astype(int)\n",
    "\n",
    "    return clustering_result_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_result_km = count_clusters(atn_km_df)\n",
    "clustering_result_gmm = count_clusters(atn_gmm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means\n",
      "7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "6 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'DOD-ADNI', 'PharmaCog']\n",
      "7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "6 ['ADNI', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "6 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'PharmaCog']\n",
      "GMM\n",
      "7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "5 ['ADNI', 'ARWIBO', 'NACC', 'DOD-ADNI', 'PharmaCog']\n",
      "5 ['ADNI', 'EDSD', 'NACC', 'JADNI', 'PharmaCog']\n",
      "6 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'PharmaCog']\n",
      "6 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'PharmaCog']\n"
     ]
    }
   ],
   "source": [
    "print(\"K-Means\")\n",
    "for i in clustering_result_km.keys():\n",
    "    print(len(clustering_result_km[i].index), list(clustering_result_km[i].index))\n",
    "    \n",
    "print(\"GMM\")\n",
    "for i in clustering_result_gmm.keys():\n",
    "    print(len(clustering_result_gmm[i].index), list(clustering_result_gmm[i].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A-T-N-', 'A+T-N-', 'A+T+N+', 'A-T+N+', 'A+T+N-', 'A-T-N+', 'A+T-N+'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_result_km.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A-T-N-', 'A+T-N-', 'A+T+N+', 'A-T+N+', 'A+T+N-', 'A+T-N+', 'A-T-N+'])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_result_gmm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADNI</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDSD</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARWIBO</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACC</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JADNI</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PharmaCog</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1  2  3  4  5\n",
       "ADNI       1  2  1  2  2  0\n",
       "EDSD       0  2  0  3  2  1\n",
       "ARWIBO     7  1  1  1  4  0\n",
       "NACC       7  3  7  7  3  0\n",
       "JADNI      1  3  0  0  1  0\n",
       "PharmaCog  0  2  2  1  0  0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_result_gmm['A+T-N+']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
