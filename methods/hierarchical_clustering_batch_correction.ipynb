{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from collections import Counter\n",
    "import os\n",
    "import glob\n",
    "import copy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn import metrics\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from combat.pycombat import pycombat\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read every cohort study file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [pd.read_csv(file, index_col=0, low_memory=False) for file in sorted(glob.glob('../cohort_studies_full_data/' + \"/*.\"+'csv'))]\n",
    "cohorts = [file.split(\".\")[0] for file in sorted(os.listdir('../cohort_studies_full_data/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all cohorts as a dataframe\n",
    "cohort_studies = dict()\n",
    "# dfsss = dict()\n",
    "\n",
    "for cohort, dataset in zip(cohorts, datasets):\n",
    "    cohort_n = cohort.split(\"_MERGE\")[0]\n",
    "    cohort_studies[cohort_n] = dataset.loc[dataset['Months']==0].copy() # reduce to BL visit\n",
    "#     dfsss[cohort_n] = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_sub = [pd.read_csv(file, index_col=0, low_memory=False) for file in sorted(glob.glob('../preprocessed_datasets/' + \"/*.\"+'csv'))]\n",
    "cohorts_sub = [file.split(\".\")[0] for file in sorted(os.listdir('../preprocessed_datasets/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all cohorts as a dataframe\n",
    "cohort_studies_sub = dict()\n",
    "\n",
    "for cohort, dataset in zip(cohorts_sub, datasets_sub):\n",
    "    cohort_studies_sub[cohort] = dataset.loc[dataset['Months']==0].copy() # reduce to BL visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the preprocessed columns from sub table of each dataset to the main table of dataset\n",
    "for i in cohort_studies:\n",
    "#     cols = cohort_studies_sub[i].columns.difference(cohort_studies[i].columns)\n",
    "    cols = ['Age', 'Sex', 'Education', 'APOE4', 'CDR', 'Race']\n",
    "    \n",
    "    for col in cols:\n",
    "        \n",
    "        if col in cohort_studies_sub[i].columns:\n",
    "            cohort_studies[i][col] = cohort_studies_sub[i][col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read harmonized mapping tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality = [pd.read_csv(file, sep=',') for file in sorted(glob.glob('../feature_tables' + \"/*.\"+'csv'))]\n",
    "name = [file.split(\".\")[0] for file in sorted(os.listdir('../feature_tables'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all modalities as a dataframe\n",
    "mappings = dict()\n",
    "\n",
    "for moda, na in zip(modality, name):\n",
    "    mappings[na.split(' - ')[1]] = moda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "harmonized_features = pd.concat(mappings, ignore_index=True) # combine all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude categorical and taboo features\n",
    "harmonized_features = harmonized_features.loc[(harmonized_features['Rank']!=1) & (harmonized_features['Rank']!=2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the feature availability files for all cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ava_mapp = [pd.read_csv(file, sep='\\t') for file in sorted(glob.glob('../feature_availability_in_cohorts' + \"/*.\"+'tsv'))]\n",
    "tablesss = [file.split(\".\")[0] for file in sorted(os.listdir('../feature_availability_in_cohorts'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains all modalities as a dataframe\n",
    "available_features = dict()\n",
    "\n",
    "for modal, df in zip(tablesss, ava_mapp):\n",
    "    available_features[modal] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_features = pd.concat(available_features, ignore_index=True) # combine all tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_features.replace({0: np.nan}, inplace=True) # 0 indicates that the feature was not measured "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read cutoffs obtained using all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_method = [pd.read_csv(file, index_col=0, low_memory=False) for file in sorted(glob.glob('../results/cutoffs/' + \"/*.\"+'csv'))]\n",
    "method_name = [file.split(\".\")[0] for file in sorted(os.listdir('../results/cutoffs/'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary that contains each cutoff table as a dataframe\n",
    "cutoffs_ = dict()\n",
    "\n",
    "for tm, mn in zip(table_method, method_name):\n",
    "    cutoffs_[mn] = tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cutoffs_['km_cutoffs'].rename(columns={col: col.split('_')[0]}, inplace=True) for col in cutoffs_['km_cutoffs'].columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecetion of cohort studies for A/T/N assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the patient that have CSF biomarker, disregard the diagnostic status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "atn = pd.DataFrame(index=available_features['csf'].iloc[:3].replace({0: np.nan}).dropna(axis=1).columns[1:].to_list(), columns=mappings['csf'].Feature.loc[0:2].to_list()+([\"Total\"]))\n",
    "# atn = pd.DataFrame(index=cohort_studies, columns=['A', 'T', 'N'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in atn.index:\n",
    "    for feat in mappings['csf'][cohort].loc[0:2].dropna().to_list():\n",
    "        if feat in cohort_studies[cohort].columns:\n",
    "            atn.loc[cohort, mappings['csf'].loc[mappings['csf'][cohort]==feat, 'Feature']] = len(cohort_studies[cohort][feat].dropna())\n",
    "            atn.loc[cohort, 'Total'] = len(cohort_studies[cohort][mappings['csf'][cohort].loc[0:2].dropna().to_list()].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = pd.DataFrame(index=available_features['csf'].iloc[:3].replace({0: np.nan}).dropna(axis=1).columns[1:].to_list(), columns=cohort_studies['ADNI']['Diagnosis'].dropna().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in diag.index:\n",
    "    for dia in diag.columns:\n",
    "        diag.loc[cohort, dia] = len(cohort_studies[cohort].loc[cohort_studies[cohort]['Diagnosis']==dia][mappings['csf'][cohort].loc[0:2].dropna().to_list()].dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the empty columns from all cohorts that we are intrested in\n",
    "### Remove the participant without all 3 CSF biomarkers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cohorts = dict()\n",
    "\n",
    "for coh in diag.index:\n",
    "    selected_cohorts[coh] = cohort_studies[coh].dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_feats = dict()\n",
    "\n",
    "# existing_features.set_index('Feature', inplace=True)\n",
    "\n",
    "for feat in existing_features.Feature:\n",
    "    total_feats[feat] = existing_features.loc[existing_features.Feature==feat][selected_cohorts].dropna(axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in atn.index:\n",
    "    feat = mappings['csf'][cohort].loc[0:2].dropna().to_list()\n",
    "    cohort_studies[cohort] = cohort_studies[cohort].dropna(subset=feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Some features have suffix due to merging tables for certain cohorts, first investigate if all the harmonized features are in cohorts. Rename the ones that have suffix so it can be compatible to work with our harmonized names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_studies['ADNI'] = cohort_studies['ADNI'].rename(columns={'PTEDUCAT_x': 'PTEDUCAT', 'TRABSCOR_bl': 'TRABSCOR', 'LDELTOTAL_BL': 'LDELTOTAL'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSF biomarkers, two classes, normal vs abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modality_ = ['clinical_i', 'clinical_ii','hippocampus', 'csf']\n",
    "# modality_ = ['basal_ganglia', 'brain_poles_volume', 'cerebellum', 'clinical_i', \n",
    "#             'clinical_ii', 'csf', 'diencephalus', 'general_brain', \n",
    "#             'mri_others', 'pet', 'plasma', 'ventricles', 'hippocampus']\n",
    "modality_ = ['basal_ganglia', 'brain_poles_volume', 'cerebellum', 'csf', 'diencephalus', 'general_brain', \n",
    "            'mri_others', 'pet', 'plasma', 'ventricles', 'hippocampus']\n",
    "\n",
    "selected_feat = dict()\n",
    "\n",
    "for i in modality_:\n",
    "    selected_feat[i] = mappings[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe containing all the mapped features\n",
    "features_all = pd.concat(selected_feat, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all = features_all[atn.index.union(['Feature', 'Rank'])] # subset the cohorts of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the features that are not available in all studies\n",
    "features_all = features_all.loc[features_all['Feature'].isin(existing_features[atn.index.union(['Feature'])].dropna(how='all')['Feature'].to_list())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert MRI measurements to mm3, same as ADNI and other cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_nacc = ['basal_ganglia', 'brain_poles_volume', 'cerebellum', 'diencephalus', 'general_brain', \n",
    "            'mri_others', 'pet', 'plasma', 'ventricles', 'hippocampus']\n",
    "\n",
    "for i in mri_nacc:\n",
    "    \n",
    "    for variable in mappings[i][['Feature', 'NACC']].dropna()['Feature'].to_list():\n",
    "        \n",
    "        if \"Volume\" in variable:\n",
    "            nacc_var = mappings[i].loc[mappings[i]['Feature']==variable, 'NACC']\n",
    "            cohort_studies['NACC'][nacc_var] = cohort_studies['NACC'][nacc_var] * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "nacc_mri_to_convert = list()\n",
    "\n",
    "for i in mri_nacc:\n",
    "    \n",
    "    for feat_ in mappings[i]['NACC'].dropna().to_list():\n",
    "        nacc_mri_to_convert.append(feat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohort_studies['NACC'][nacc_mri_to_convert].dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rank 1 --> Categorical features\n",
    "* Rank 2 --> Taboo features: some categorical and some numerical\n",
    "* Rank nan --> Numerical features \n",
    "\n",
    "replace nan with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all['Rank'].replace({np.nan: 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_all.replace({\"No total score.\": np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix PharmaCog column names\n",
    "for i in cohort_studies['PharmaCog'].columns:\n",
    "    if \"\\xa0\" in i:\n",
    "        new = str(i).replace(u'\\xa0', u'')\n",
    "        cohort_studies['PharmaCog'].rename(columns={i: new}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'MCI': 145})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(cohort_studies['PharmaCog']['Diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_atn_participants(dfss, cohorts, thresholds, features):\n",
    "    \"\"\"cohorts: list of cohort names \n",
    "       dfss: dictionary of cohorts where each key is the name of a cohort\n",
    "       thresholds: cutoff values obtained using a methodology\n",
    "       \n",
    "       Select the features and participants and categorize the participant into ATN profiles using thresholds\n",
    "       obtained from each methodology.\n",
    "       \n",
    "       return a df which contain the combination of paticipant from the selected cohorts while harmonizing\n",
    "       the features names.\n",
    "    \"\"\"\n",
    "    \n",
    "    # make a list of additional features to be investigated \n",
    "#     additional_feat = ['Age', 'Sex', 'Education', 'APOE4', 'CDR', 'Race']\n",
    "    additional_feat = ['APOE4']\n",
    "\n",
    "    # make an empty dictionary to add the datasets to\n",
    "    df_= pd.DataFrame(columns=set(features.loc[features['Rank']==0]\n",
    "                                  [cohorts + ['Feature']].dropna()['Feature']).difference(['Feature'] + list(thresholds.columns)).union(additional_feat))\n",
    "   \n",
    "    for i in cohorts:\n",
    "#         print(i)\n",
    "\n",
    "        dfs = dict()\n",
    "        dfs[i] = dfss[i].copy() # make a copy of the dataset of interest\n",
    "        # select the subset of datasets with features to be investigated\n",
    "        dfs[i] = dfs[i][features.loc[features['Rank']==0][cohorts + ['Feature']].dropna()[i].to_list() + additional_feat].dropna(axis=1, how='all')\n",
    "        # rename all the columns so we can concat the datasets later\n",
    "        [dfs[i].rename(columns={col: coln}, inplace=True) for col, coln in \n",
    "         zip(features.loc[features['Rank']==0][cohorts + ['Feature']].dropna()[i].to_list(), \n",
    "             features.loc[features['Rank']==0][cohorts + ['Feature']].dropna()['Feature'].to_list())]\n",
    "        dfs[i]['Cohort'] = i # add a cohort name column\n",
    "        # change the datatype to str as these are categorical features. astype doesn't work as it will include nan values\n",
    "        dfs[i] = dfs[i].replace({'APOE4': {0.0: '0', 2.0: '2', 1.0: '1'}}) \n",
    "\n",
    "        if i!='NACC':\n",
    "            \n",
    "            for biomarker in thresholds.columns:\n",
    "                # select the cutoff value for each biomarker for each cohort\n",
    "                threshold = thresholds.loc[i][biomarker]\n",
    "\n",
    "                # dichotomize the participants\n",
    "                if biomarker == 'pTau in CSF': \n",
    "                    dfs[i].loc[dfs[i][biomarker]>threshold, \"T\"] = 'T+'\n",
    "                    dfs[i].loc[dfs[i][biomarker]<threshold, \"T\"] = 'T-'\n",
    "\n",
    "                elif biomarker == 'tTau in CSF': \n",
    "                    dfs[i].loc[dfs[i][biomarker]>threshold, \"N\"] = 'N+'\n",
    "                    dfs[i].loc[dfs[i][biomarker]<threshold, \"N\"] = 'N-'\n",
    "\n",
    "                else: \n",
    "                    dfs[i].loc[dfs[i][biomarker]<threshold, \"A\"] = 'A+'\n",
    "                    dfs[i].loc[dfs[i][biomarker]>threshold, \"A\"] = 'A-'\n",
    "\n",
    "            # join the 3 columns to make the final ATN categorie                                 \n",
    "            dfs[i]['ATN'] = dfs[i]['A'] + dfs[i]['T'] + dfs[i]['N']\n",
    "            # remove the columns that we are not interested in\n",
    "            dfs[i] = dfs[i][dfs[i].columns.difference(['A', 'T', 'N', 'Mini-Mental State Examination (MMSE)'] + list(thresholds.columns))]\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            elisa_index = cohort_studies[i].loc[(cohort_studies[i]['CSFTTMD']==1)].index\n",
    "            xmap_index = cohort_studies[i].loc[(cohort_studies[i]['CSFTTMD']==2)].index\n",
    "            \n",
    "            for biomarker in thresholds.columns:\n",
    "                # select the cutoff value for each biomarker for each cohort\n",
    "                elisa = thresholds.loc[i + \"_ELISA\"][biomarker] # ELISA\n",
    "                xmap = thresholds.loc[i + \"_XMAP\"][biomarker] #XMAP\n",
    "\n",
    "                # dichotomize the participants\n",
    "                if biomarker == 'pTau in CSF': \n",
    "                    \n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]>elisa), \"T\"] = 'T+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]<elisa), \"T\"] = 'T-'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]>xmap), \"T\"] = 'T+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]<xmap), \"T\"] = 'T-'\n",
    "\n",
    "                elif biomarker == 'tTau in CSF': \n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]>elisa), \"N\"] = 'N+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]<elisa), \"N\"] = 'N-'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]>xmap), \"N\"] = 'N+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]<xmap), \"N\"] = 'N-'\n",
    "\n",
    "                else: \n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]<elisa), \"A\"] = 'A+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(elisa_index)) & (dfs[i][biomarker]>elisa), \"A\"] = 'A-'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]<xmap), \"A\"] = 'A+'\n",
    "                    dfs[i].loc[(dfs[i].index.isin(xmap_index)) & (dfs[i][biomarker]>xmap), \"A\"] = 'A-'\n",
    "\n",
    "            # join the 3 columns to make the final ATN categorie                                 \n",
    "            dfs[i]['ATN'] = dfs[i]['A'] + dfs[i]['T'] + dfs[i]['N']\n",
    "            # remove the columns that we are not interested in\n",
    "            dfs[i] = dfs[i][dfs[i].columns.difference(['A', 'T', 'N', 'Mini-Mental State Examination (MMSE)', 'Trail Making Test (TMT) A', 'Verbal fluency tests (Semantic) Animal'] + list(thresholds.columns))]\n",
    "            \n",
    "#         print(dfs[i])\n",
    "\n",
    "        \n",
    "        df_ = pd.concat([df_, dfs[i]])\n",
    "#         print(df_)\n",
    "#         df_ = df_.dropna(axis=1, thresh=len(df_.index)/2)\n",
    "#         print(df_)\n",
    "    \n",
    "    df_ = df_.dropna(axis=1, how='all')\n",
    "    df_ = df_.dropna(axis=1, thresh=1200)\n",
    "\n",
    "    df_ = df_.dropna()\n",
    "\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_df_km = select_atn_participants(cohort_studies, ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog'], cutoffs_['km_cutoffs'], features_all)\n",
    "clustering_df_gmm = select_atn_participants(cohort_studies, ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog'], cutoffs_['gmm_cutoffs'], features_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exclude CSF Volume as it seems wrong in the NACC dataset and that could potentially add bias to our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_df_km = clustering_df_km[clustering_df_km.columns.difference(['Cerebrospinal Fluid Volume'])]\n",
    "clustering_df_gmm = clustering_df_gmm[clustering_df_gmm.columns.difference(['Cerebrospinal Fluid Volume'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch effect correstion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7 batches.\n",
      "Adjusting for 0 covariate(s) or covariate level(s).\n",
      "Standardizing Data across genes.\n",
      "Fitting L/S model and finding priors.\n",
      "Finding parametric adjustments.\n",
      "Adjusting the Data\n",
      "Found 7 batches.\n",
      "Adjusting for 0 covariate(s) or covariate level(s).\n",
      "Standardizing Data across genes.\n",
      "Fitting L/S model and finding priors.\n",
      "Finding parametric adjustments.\n",
      "Adjusting the Data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.9/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "km_corrected = pycombat(clustering_df_km.drop(columns=['ATN', 'Cohort', 'APOE4']).transpose(), \n",
    "         batch=clustering_df_km['Cohort']).transpose()\n",
    "\n",
    "gmm_corrected = pycombat(clustering_df_gmm.drop(columns=['ATN', 'Cohort', 'APOE4']).transpose(), \n",
    "         batch=clustering_df_gmm['Cohort']).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_corrected[['ATN', 'Cohort', 'APOE4']] = clustering_df_km[['ATN', 'Cohort', 'APOE4']]\n",
    "gmm_corrected[['ATN', 'Cohort', 'APOE4']] = clustering_df_gmm[['ATN', 'Cohort', 'APOE4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm_corrected.to_csv(\"../results/batch_effect_corrected_dfs/gmm.csv\")\n",
    "km_corrected.to_csv(\"../results/batch_effect_corrected_dfs/km.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cortical White Matter Volume</th>\n",
       "      <th>Left Caudal Anterior Cingulate Mean Cortical Thickness</th>\n",
       "      <th>Left Caudal Middle Frontal Mean Cortical Thickness</th>\n",
       "      <th>Left Cuneus Mean Cortical Thickness</th>\n",
       "      <th>Left Fusiform Mean Cortical Thickness</th>\n",
       "      <th>Left Hippocampus Volume</th>\n",
       "      <th>Left Inferiorparietal Mean Cortical Thickness</th>\n",
       "      <th>Left Inferiortemporal Mean Cortical Thickness</th>\n",
       "      <th>Left Insula Mean Cortical Thickness</th>\n",
       "      <th>Left Isthmus Cingulate Mean Cortical Thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>Right Superiorparietal Mean Cortical Thickness</th>\n",
       "      <th>Right Supramarginal Gray Matter Volume</th>\n",
       "      <th>Right Supramarginal Mean Cortical Thickness</th>\n",
       "      <th>Right Transverse Temporal Grey Matter Volume</th>\n",
       "      <th>Right Transverse Temporal Mean Cortical Thickness</th>\n",
       "      <th>Third Ventricle Volume</th>\n",
       "      <th>ATN</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>APOE4</th>\n",
       "      <th>Cohort_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>529614.559202</td>\n",
       "      <td>2.803507</td>\n",
       "      <td>2.350412</td>\n",
       "      <td>1.844182</td>\n",
       "      <td>2.844034</td>\n",
       "      <td>3833.180181</td>\n",
       "      <td>2.532128</td>\n",
       "      <td>3.022473</td>\n",
       "      <td>3.044157</td>\n",
       "      <td>2.631526</td>\n",
       "      <td>...</td>\n",
       "      <td>2.177215</td>\n",
       "      <td>8318.204123</td>\n",
       "      <td>2.452891</td>\n",
       "      <td>1042.573251</td>\n",
       "      <td>2.290788</td>\n",
       "      <td>922.094185</td>\n",
       "      <td>A-T-N-</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>547839.641903</td>\n",
       "      <td>2.002942</td>\n",
       "      <td>2.361987</td>\n",
       "      <td>1.518422</td>\n",
       "      <td>2.568734</td>\n",
       "      <td>4391.308766</td>\n",
       "      <td>2.159833</td>\n",
       "      <td>2.691001</td>\n",
       "      <td>3.275687</td>\n",
       "      <td>2.115724</td>\n",
       "      <td>...</td>\n",
       "      <td>1.886296</td>\n",
       "      <td>10889.675353</td>\n",
       "      <td>2.287566</td>\n",
       "      <td>738.853823</td>\n",
       "      <td>1.829301</td>\n",
       "      <td>1203.415027</td>\n",
       "      <td>A+T-N-</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2026</th>\n",
       "      <td>411125.456674</td>\n",
       "      <td>2.417404</td>\n",
       "      <td>1.929103</td>\n",
       "      <td>1.619870</td>\n",
       "      <td>2.334173</td>\n",
       "      <td>3025.389642</td>\n",
       "      <td>2.030625</td>\n",
       "      <td>2.305709</td>\n",
       "      <td>2.815468</td>\n",
       "      <td>1.766799</td>\n",
       "      <td>...</td>\n",
       "      <td>1.645463</td>\n",
       "      <td>6289.481943</td>\n",
       "      <td>1.850141</td>\n",
       "      <td>518.068852</td>\n",
       "      <td>1.957553</td>\n",
       "      <td>1772.106621</td>\n",
       "      <td>A-T-N-</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2031</th>\n",
       "      <td>455027.937947</td>\n",
       "      <td>2.638813</td>\n",
       "      <td>2.280966</td>\n",
       "      <td>1.388794</td>\n",
       "      <td>2.458860</td>\n",
       "      <td>3258.545021</td>\n",
       "      <td>2.085374</td>\n",
       "      <td>2.648190</td>\n",
       "      <td>2.850979</td>\n",
       "      <td>2.626107</td>\n",
       "      <td>...</td>\n",
       "      <td>1.711532</td>\n",
       "      <td>8367.736560</td>\n",
       "      <td>2.292158</td>\n",
       "      <td>750.061182</td>\n",
       "      <td>1.605682</td>\n",
       "      <td>2315.590254</td>\n",
       "      <td>A-T-N-</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>469788.645705</td>\n",
       "      <td>2.341055</td>\n",
       "      <td>2.412914</td>\n",
       "      <td>1.708918</td>\n",
       "      <td>2.513180</td>\n",
       "      <td>2759.221112</td>\n",
       "      <td>2.269332</td>\n",
       "      <td>2.668984</td>\n",
       "      <td>2.809786</td>\n",
       "      <td>2.216500</td>\n",
       "      <td>...</td>\n",
       "      <td>1.985401</td>\n",
       "      <td>8148.529177</td>\n",
       "      <td>2.294454</td>\n",
       "      <td>574.105646</td>\n",
       "      <td>1.841359</td>\n",
       "      <td>2794.541508</td>\n",
       "      <td>A+T-N-</td>\n",
       "      <td>ADNI</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-37-024</th>\n",
       "      <td>385681.221686</td>\n",
       "      <td>2.274259</td>\n",
       "      <td>1.787558</td>\n",
       "      <td>1.417165</td>\n",
       "      <td>1.833636</td>\n",
       "      <td>2776.094627</td>\n",
       "      <td>1.659645</td>\n",
       "      <td>1.986286</td>\n",
       "      <td>1.432207</td>\n",
       "      <td>1.970457</td>\n",
       "      <td>...</td>\n",
       "      <td>1.694967</td>\n",
       "      <td>6879.671961</td>\n",
       "      <td>2.010772</td>\n",
       "      <td>536.037719</td>\n",
       "      <td>1.549538</td>\n",
       "      <td>2415.063230</td>\n",
       "      <td>A+T-N-</td>\n",
       "      <td>PharmaCog</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-37-025</th>\n",
       "      <td>610651.113209</td>\n",
       "      <td>2.744791</td>\n",
       "      <td>2.138136</td>\n",
       "      <td>1.477410</td>\n",
       "      <td>1.640976</td>\n",
       "      <td>2608.328963</td>\n",
       "      <td>1.855343</td>\n",
       "      <td>2.080572</td>\n",
       "      <td>2.563884</td>\n",
       "      <td>1.913397</td>\n",
       "      <td>...</td>\n",
       "      <td>1.460069</td>\n",
       "      <td>7300.029396</td>\n",
       "      <td>1.840256</td>\n",
       "      <td>644.903612</td>\n",
       "      <td>1.690487</td>\n",
       "      <td>2926.539009</td>\n",
       "      <td>A-T-N-</td>\n",
       "      <td>PharmaCog</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-37-026</th>\n",
       "      <td>481812.993949</td>\n",
       "      <td>2.797072</td>\n",
       "      <td>2.259025</td>\n",
       "      <td>1.517573</td>\n",
       "      <td>2.513016</td>\n",
       "      <td>3800.528725</td>\n",
       "      <td>2.116274</td>\n",
       "      <td>2.813910</td>\n",
       "      <td>3.135112</td>\n",
       "      <td>2.221522</td>\n",
       "      <td>...</td>\n",
       "      <td>1.833771</td>\n",
       "      <td>8628.527455</td>\n",
       "      <td>2.426405</td>\n",
       "      <td>855.377674</td>\n",
       "      <td>2.254280</td>\n",
       "      <td>1580.597557</td>\n",
       "      <td>A+T+N+</td>\n",
       "      <td>PharmaCog</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-37-027</th>\n",
       "      <td>489845.272363</td>\n",
       "      <td>2.587947</td>\n",
       "      <td>2.101869</td>\n",
       "      <td>1.678224</td>\n",
       "      <td>2.523156</td>\n",
       "      <td>3626.844946</td>\n",
       "      <td>2.246740</td>\n",
       "      <td>2.803434</td>\n",
       "      <td>2.811775</td>\n",
       "      <td>2.552472</td>\n",
       "      <td>...</td>\n",
       "      <td>1.983251</td>\n",
       "      <td>8030.123888</td>\n",
       "      <td>2.266546</td>\n",
       "      <td>837.751767</td>\n",
       "      <td>2.037437</td>\n",
       "      <td>2133.736528</td>\n",
       "      <td>A+T-N-</td>\n",
       "      <td>PharmaCog</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PT-37-028</th>\n",
       "      <td>482528.532968</td>\n",
       "      <td>2.295172</td>\n",
       "      <td>2.319469</td>\n",
       "      <td>1.497491</td>\n",
       "      <td>2.462316</td>\n",
       "      <td>3803.101818</td>\n",
       "      <td>2.116274</td>\n",
       "      <td>2.604385</td>\n",
       "      <td>2.844109</td>\n",
       "      <td>2.301407</td>\n",
       "      <td>...</td>\n",
       "      <td>1.791062</td>\n",
       "      <td>8497.890056</td>\n",
       "      <td>2.128002</td>\n",
       "      <td>648.014067</td>\n",
       "      <td>2.460282</td>\n",
       "      <td>1876.546436</td>\n",
       "      <td>A+T-N-</td>\n",
       "      <td>PharmaCog</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1331 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Cortical White Matter Volume  \\\n",
       "2002                      529614.559202   \n",
       "2022                      547839.641903   \n",
       "2026                      411125.456674   \n",
       "2031                      455027.937947   \n",
       "2042                      469788.645705   \n",
       "...                                 ...   \n",
       "PT-37-024                 385681.221686   \n",
       "PT-37-025                 610651.113209   \n",
       "PT-37-026                 481812.993949   \n",
       "PT-37-027                 489845.272363   \n",
       "PT-37-028                 482528.532968   \n",
       "\n",
       "           Left Caudal Anterior Cingulate Mean Cortical Thickness  \\\n",
       "2002                                                2.803507        \n",
       "2022                                                2.002942        \n",
       "2026                                                2.417404        \n",
       "2031                                                2.638813        \n",
       "2042                                                2.341055        \n",
       "...                                                      ...        \n",
       "PT-37-024                                           2.274259        \n",
       "PT-37-025                                           2.744791        \n",
       "PT-37-026                                           2.797072        \n",
       "PT-37-027                                           2.587947        \n",
       "PT-37-028                                           2.295172        \n",
       "\n",
       "           Left Caudal Middle Frontal Mean Cortical Thickness  \\\n",
       "2002                                                2.350412    \n",
       "2022                                                2.361987    \n",
       "2026                                                1.929103    \n",
       "2031                                                2.280966    \n",
       "2042                                                2.412914    \n",
       "...                                                      ...    \n",
       "PT-37-024                                           1.787558    \n",
       "PT-37-025                                           2.138136    \n",
       "PT-37-026                                           2.259025    \n",
       "PT-37-027                                           2.101869    \n",
       "PT-37-028                                           2.319469    \n",
       "\n",
       "           Left Cuneus Mean Cortical Thickness  \\\n",
       "2002                                  1.844182   \n",
       "2022                                  1.518422   \n",
       "2026                                  1.619870   \n",
       "2031                                  1.388794   \n",
       "2042                                  1.708918   \n",
       "...                                        ...   \n",
       "PT-37-024                             1.417165   \n",
       "PT-37-025                             1.477410   \n",
       "PT-37-026                             1.517573   \n",
       "PT-37-027                             1.678224   \n",
       "PT-37-028                             1.497491   \n",
       "\n",
       "           Left Fusiform Mean Cortical Thickness  Left Hippocampus Volume  \\\n",
       "2002                                    2.844034              3833.180181   \n",
       "2022                                    2.568734              4391.308766   \n",
       "2026                                    2.334173              3025.389642   \n",
       "2031                                    2.458860              3258.545021   \n",
       "2042                                    2.513180              2759.221112   \n",
       "...                                          ...                      ...   \n",
       "PT-37-024                               1.833636              2776.094627   \n",
       "PT-37-025                               1.640976              2608.328963   \n",
       "PT-37-026                               2.513016              3800.528725   \n",
       "PT-37-027                               2.523156              3626.844946   \n",
       "PT-37-028                               2.462316              3803.101818   \n",
       "\n",
       "           Left Inferiorparietal Mean Cortical Thickness  \\\n",
       "2002                                            2.532128   \n",
       "2022                                            2.159833   \n",
       "2026                                            2.030625   \n",
       "2031                                            2.085374   \n",
       "2042                                            2.269332   \n",
       "...                                                  ...   \n",
       "PT-37-024                                       1.659645   \n",
       "PT-37-025                                       1.855343   \n",
       "PT-37-026                                       2.116274   \n",
       "PT-37-027                                       2.246740   \n",
       "PT-37-028                                       2.116274   \n",
       "\n",
       "           Left Inferiortemporal Mean Cortical Thickness  \\\n",
       "2002                                            3.022473   \n",
       "2022                                            2.691001   \n",
       "2026                                            2.305709   \n",
       "2031                                            2.648190   \n",
       "2042                                            2.668984   \n",
       "...                                                  ...   \n",
       "PT-37-024                                       1.986286   \n",
       "PT-37-025                                       2.080572   \n",
       "PT-37-026                                       2.813910   \n",
       "PT-37-027                                       2.803434   \n",
       "PT-37-028                                       2.604385   \n",
       "\n",
       "           Left Insula Mean Cortical Thickness  \\\n",
       "2002                                  3.044157   \n",
       "2022                                  3.275687   \n",
       "2026                                  2.815468   \n",
       "2031                                  2.850979   \n",
       "2042                                  2.809786   \n",
       "...                                        ...   \n",
       "PT-37-024                             1.432207   \n",
       "PT-37-025                             2.563884   \n",
       "PT-37-026                             3.135112   \n",
       "PT-37-027                             2.811775   \n",
       "PT-37-028                             2.844109   \n",
       "\n",
       "           Left Isthmus Cingulate Mean Cortical Thickness  ...  \\\n",
       "2002                                             2.631526  ...   \n",
       "2022                                             2.115724  ...   \n",
       "2026                                             1.766799  ...   \n",
       "2031                                             2.626107  ...   \n",
       "2042                                             2.216500  ...   \n",
       "...                                                   ...  ...   \n",
       "PT-37-024                                        1.970457  ...   \n",
       "PT-37-025                                        1.913397  ...   \n",
       "PT-37-026                                        2.221522  ...   \n",
       "PT-37-027                                        2.552472  ...   \n",
       "PT-37-028                                        2.301407  ...   \n",
       "\n",
       "           Right Superiorparietal Mean Cortical Thickness  \\\n",
       "2002                                             2.177215   \n",
       "2022                                             1.886296   \n",
       "2026                                             1.645463   \n",
       "2031                                             1.711532   \n",
       "2042                                             1.985401   \n",
       "...                                                   ...   \n",
       "PT-37-024                                        1.694967   \n",
       "PT-37-025                                        1.460069   \n",
       "PT-37-026                                        1.833771   \n",
       "PT-37-027                                        1.983251   \n",
       "PT-37-028                                        1.791062   \n",
       "\n",
       "           Right Supramarginal Gray Matter Volume  \\\n",
       "2002                                  8318.204123   \n",
       "2022                                 10889.675353   \n",
       "2026                                  6289.481943   \n",
       "2031                                  8367.736560   \n",
       "2042                                  8148.529177   \n",
       "...                                           ...   \n",
       "PT-37-024                             6879.671961   \n",
       "PT-37-025                             7300.029396   \n",
       "PT-37-026                             8628.527455   \n",
       "PT-37-027                             8030.123888   \n",
       "PT-37-028                             8497.890056   \n",
       "\n",
       "           Right Supramarginal Mean Cortical Thickness  \\\n",
       "2002                                          2.452891   \n",
       "2022                                          2.287566   \n",
       "2026                                          1.850141   \n",
       "2031                                          2.292158   \n",
       "2042                                          2.294454   \n",
       "...                                                ...   \n",
       "PT-37-024                                     2.010772   \n",
       "PT-37-025                                     1.840256   \n",
       "PT-37-026                                     2.426405   \n",
       "PT-37-027                                     2.266546   \n",
       "PT-37-028                                     2.128002   \n",
       "\n",
       "           Right Transverse Temporal Grey Matter Volume  \\\n",
       "2002                                        1042.573251   \n",
       "2022                                         738.853823   \n",
       "2026                                         518.068852   \n",
       "2031                                         750.061182   \n",
       "2042                                         574.105646   \n",
       "...                                                 ...   \n",
       "PT-37-024                                    536.037719   \n",
       "PT-37-025                                    644.903612   \n",
       "PT-37-026                                    855.377674   \n",
       "PT-37-027                                    837.751767   \n",
       "PT-37-028                                    648.014067   \n",
       "\n",
       "           Right Transverse Temporal Mean Cortical Thickness  \\\n",
       "2002                                                2.290788   \n",
       "2022                                                1.829301   \n",
       "2026                                                1.957553   \n",
       "2031                                                1.605682   \n",
       "2042                                                1.841359   \n",
       "...                                                      ...   \n",
       "PT-37-024                                           1.549538   \n",
       "PT-37-025                                           1.690487   \n",
       "PT-37-026                                           2.254280   \n",
       "PT-37-027                                           2.037437   \n",
       "PT-37-028                                           2.460282   \n",
       "\n",
       "           Third Ventricle Volume     ATN     Cohort  APOE4  Cohort_number  \n",
       "2002                   922.094185  A-T-N-       ADNI      0            0.0  \n",
       "2022                  1203.415027  A+T-N-       ADNI      1            0.0  \n",
       "2026                  1772.106621  A-T-N-       ADNI      0            0.0  \n",
       "2031                  2315.590254  A-T-N-       ADNI      0            0.0  \n",
       "2042                  2794.541508  A+T-N-       ADNI      0            0.0  \n",
       "...                           ...     ...        ...    ...            ...  \n",
       "PT-37-024             2415.063230  A+T-N-  PharmaCog      0            6.0  \n",
       "PT-37-025             2926.539009  A-T-N-  PharmaCog      0            6.0  \n",
       "PT-37-026             1580.597557  A+T+N+  PharmaCog      0            6.0  \n",
       "PT-37-027             2133.736528  A+T-N-  PharmaCog      0            6.0  \n",
       "PT-37-028             1876.546436  A+T-N-  PharmaCog      1            6.0  \n",
       "\n",
       "[1331 rows x 108 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with PdfPages('../results/boxplot_batch_correction/batch_effect.pdf') as pdf:\n",
    "\n",
    "#     for i in clustering_df_km.columns.difference(['ATN', 'APOE4', 'Cohort']):\n",
    "#         fig, axes = plt.subplots(1,2, figsize=(20, 8))\n",
    "\n",
    "#         sns.boxplot(data=clustering_df_km, x='Cohort', y=i, ax=axes[0])\n",
    "#         sns.boxplot(data=km_corrected, x='Cohort', y=i, ax=axes[1])\n",
    "#         axes[0].set_title(\"Raw measurements\")\n",
    "#         axes[1].set_title(\"Corrected measurements\")\n",
    "\n",
    "#         fig.get_figure()\n",
    "#         pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with PdfPages('../results/boxplot_batch_correction/batch_effect_gmm.pdf') as pdf:\n",
    "\n",
    "#     for i in clustering_df_km.columns.difference(['ATN', 'APOE4', 'Cohort']):\n",
    "#         fig, axes = plt.subplots(1,2, figsize=(20, 8))\n",
    "\n",
    "#         sns.boxplot(data=clustering_df_gmm, x='Cohort', y=i, ax=axes[0])\n",
    "#         sns.boxplot(data=gmm_corrected, x='Cohort', y=i, ax=axes[1])\n",
    "#         axes[0].set_title(\"Raw measurements\")\n",
    "#         axes[1].set_title(\"Corrected measurements\")\n",
    "\n",
    "#         fig.get_figure()\n",
    "#         pdf.savefig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(y_true, y_pred)\n",
    "    # return purity\n",
    "    return np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atn_based_df(df):\n",
    "    \"\"\"\"\"\"\n",
    "    \n",
    "    labels_atn = dict()\n",
    "    score_atn = dict()\n",
    "    \n",
    "    # change the cohort names to int and write in a column\n",
    "    for i, j in zip(df.Cohort.unique(), range(len(df.Cohort.unique()))):\n",
    "        df.loc[df['Cohort']==i, 'Cohort_number'] = j\n",
    "    \n",
    "    # select the profiles that have over 20 participants\n",
    "    # make a dictionary where the selcted ATN profiles are key and \n",
    "    # the subset of dataframe categorized in that ATN profile is value\n",
    "    dfs_sub = {atn: df.loc[df.ATN==atn].copy() for atn in list((a) for a,b in dict(Counter(df.ATN)).items() if b >20)}\n",
    "    \n",
    "    for i in dfs_sub:\n",
    "#         print(i, len(dfs_sub[i].Cohort.unique()))\n",
    "        hierarchical_cluster = AgglomerativeClustering(n_clusters=len(dfs_sub[i].Cohort.unique()), affinity='euclidean', linkage='ward')\n",
    "        labels = hierarchical_cluster.fit_predict(dfs_sub[i][dfs_sub[i].columns.difference(['ATN', 'Cohort', 'Cohort_number'])])\n",
    "        labels_atn[i] = labels\n",
    "        score_atn[i] = purity_score(dfs_sub[i]['Cohort_number'], labels)\n",
    "     \n",
    "    return labels_atn, score_atn, dfs_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_km, score_km, atn_km_df = atn_based_df(clustering_df_km)\n",
    "labels_gmm, score_gmm, atn_gmm_df = atn_based_df(clustering_df_gmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "labels_km_t, score_km_t, atn_km_df_t = atn_based_df(km_corrected)\n",
    "labels_gmm_t, score_gmm_t, atn_gmm_df_t = atn_based_df(gmm_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Cluster purity (K-means):\")\n",
    "# score_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Cluster purity (GMM):\")\n",
    "# score_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in labels_km:\n",
    "    atn_km_df[i].loc[:, 'predicted_cohort'] = list(labels_km[i])\n",
    "\n",
    "for i_ in labels_gmm:\n",
    "    atn_gmm_df[i_].loc[:, 'predicted_cohort'] = list(labels_gmm[i_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "for i in labels_km_t:\n",
    "    atn_km_df_t[i].loc[:, 'predicted_cohort'] = list(labels_km_t[i])\n",
    "\n",
    "for i_ in labels_gmm_t:\n",
    "    atn_gmm_df_t[i_].loc[:, 'predicted_cohort'] = list(labels_gmm_t[i_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cramer(dfs):\n",
    "    \"\"\" \"\"\"\n",
    "    results = dict()\n",
    "    \n",
    "    for i in dfs:\n",
    "        df_ = dfs[i].set_index('Cohort')\n",
    "        mat = pd.crosstab(df_.index, df_['predicted_cohort'])\n",
    "#         print(i, mat)\n",
    "#         print(i, round(stats.contingency.association(mat, method='cramer'), 2))\n",
    "        results[i] = round(stats.contingency.association(mat, method='cramer'), 2)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.from_dict(calculate_cramer(atn_km_df), orient='index').transpose()[['A-T-N-', 'A-T+N+', 'A-T-N+', 'A+T+N-', 'A+T-N-', 'A+T-N+', 'A+T+N+']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame.from_dict(calculate_cramer(atn_gmm_df), orient='index').transpose()[['A-T-N-', 'A-T+N+', 'A-T-N+', 'A+T+N-', 'A+T-N-', 'A+T-N+', 'A+T+N+']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the batch-corrected ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramer_km = pd.DataFrame.from_dict(calculate_cramer(atn_km_df_t), orient='index').transpose()[['A-T-N-', 'A-T+N+', 'A-T-N+', 'A+T+N-', 'A+T-N-', 'A+T-N+', 'A+T+N+']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramer_gmm = pd.DataFrame.from_dict(calculate_cramer(atn_gmm_df_t), orient='index').transpose()[['A-T-N-', 'A-T+N+', 'A-T-N+', 'A+T+N-', 'A+T-N-', 'A+T-N+', 'A+T+N+']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip([cramer_km, cramer_gmm], ['K-Means', 'GMM']):\n",
    "    i.rename(index={0: j}, inplace=True)\n",
    "    i.to_csv(f\"../results/clustering/cramers_v/cramers_v_{j}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chi2(dfs):\n",
    "    \"\"\" \"\"\"\n",
    "    results_chi2 = dict()\n",
    "    results_p = dict()\n",
    "    results_df = dict()\n",
    "    results_ex = dict()\n",
    "    \n",
    "    for i in dfs:\n",
    "        df_ = dfs[i].set_index('Cohort')\n",
    "        mat = pd.crosstab(df_.index, df_['predicted_cohort'])\n",
    "        results_chi2[i], results_p[i], results_df[i], results_ex[i] = stats.chi2_contingency(mat, correction=True)\n",
    "        \n",
    "    return results_chi2, results_p, results_df, results_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_chi2_km, results_p_km, results_df_km, results_ex_km = calculate_chi2(atn_km_df)\n",
    "# results_chi2_gmm, results_p_gmm, results_df_gmm, results_ex_gmm = calculate_chi2(atn_gmm_df)\n",
    "\n",
    "# corrected dataframes\n",
    "results_chi2_km_t, results_p_km_t, results_df_km_t, results_ex_km_t = calculate_chi2(atn_km_df_t)\n",
    "results_chi2_gmm_t, results_p_gmm_t, results_df_gmm_t, results_ex_gmm_t = calculate_chi2(atn_gmm_df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A-T-N-': 47.2738997828431,\n",
       " 'A+T-N-': 39.86569318064662,\n",
       " 'A+T+N+': 50.74756679162755,\n",
       " 'A-T+N+': 12.767045454545453,\n",
       " 'A+T+N-': 24.40691661279897,\n",
       " 'A+T-N+': 33.557491522843705,\n",
       " 'A-T-N+': 25.86746031746032}"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_chi2_gmm_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_km = pd.DataFrame.from_dict(results_p_km_t, orient='index').transpose()[['A-T-N-', 'A-T+N+', 'A-T-N+', 'A+T+N-', 'A+T-N-', 'A+T-N+', 'A+T+N+']].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue_gmm = pd.DataFrame.from_dict(results_p_gmm_t, orient='index').transpose()[['A-T-N-', 'A-T+N+', 'A-T-N+', 'A+T+N-', 'A+T-N-', 'A+T-N+', 'A+T+N+']].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Cramer's V and P-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A-T-N-</th>\n",
       "      <th>A-T+N+</th>\n",
       "      <th>A-T-N+</th>\n",
       "      <th>A+T+N-</th>\n",
       "      <th>A+T-N-</th>\n",
       "      <th>A+T-N+</th>\n",
       "      <th>A+T+N+</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A-T-N-  A-T+N+  A-T-N+  A+T+N-  A+T-N-  A+T-N+  A+T+N+\n",
       "0     0.1    0.69    0.41    0.08     0.3    0.12    0.05"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pvalue_gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip([pvalue_km, pvalue_gmm], ['K-Means', 'GMM']):\n",
    "    i.rename(index={0: j}, inplace=True)\n",
    "    i.to_csv(f\"../results/clustering/p_value/pvalue_{j}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: One could use the crosstab instead of the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_clusters(df):\n",
    "    \n",
    "    \"\"\"df: dataframe with ATN categorization using certain method and containing cluster labels\n",
    "       return: the number of participant within each cohort and within each ATN profile assigned to each labels\"\"\"\n",
    "    \n",
    "    # make an empty dictionary of dataframes to store the results\n",
    "    clustering_result_ = {i: pd.DataFrame(index=df[i].Cohort.unique(), \n",
    "                                            columns=sorted(df[i].predicted_cohort.unique())) for i in df}\n",
    "    \n",
    "    # check the number of participants clustered to each coohort within each biomarker profile\n",
    "    for profi in df:\n",
    "    \n",
    "        for name in df[profi]['Cohort'].unique():\n",
    "            clustering_result_[profi].loc[name] = Counter(df[profi].loc[df[profi]['Cohort']==name, 'predicted_cohort'])\n",
    "            \n",
    "            \n",
    "    # replace all nan enteries with 0\n",
    "    [clustering_result_[i].replace({np.nan: 0}, inplace=True) for i in clustering_result_]\n",
    "    \n",
    "    # change enteries to integer\n",
    "    for i in clustering_result_:\n",
    "        clustering_result_[i] = clustering_result_[i].astype(int)\n",
    "\n",
    "    return clustering_result_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_result_km = count_clusters(atn_km_df_t)\n",
    "clustering_result_gmm = count_clusters(atn_gmm_df_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Means\n",
      "A-T-N- 7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "A-T+N+ 6 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'DOD-ADNI', 'PharmaCog']\n",
      "A-T-N+ 6 ['ADNI', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "A+T+N- 7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "A+T-N- 7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "A+T-N+ 6 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'PharmaCog']\n",
      "A+T+N+ 7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "GMM\n",
      "A-T-N- 7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "A-T+N+ 5 ['ADNI', 'ARWIBO', 'NACC', 'DOD-ADNI', 'PharmaCog']\n",
      "A-T-N+ 6 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'PharmaCog']\n",
      "A+T+N- 5 ['ADNI', 'EDSD', 'NACC', 'JADNI', 'PharmaCog']\n",
      "A+T-N- 7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n",
      "A+T-N+ 6 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'PharmaCog']\n",
      "A+T+N+ 7 ['ADNI', 'EDSD', 'ARWIBO', 'NACC', 'JADNI', 'DOD-ADNI', 'PharmaCog']\n"
     ]
    }
   ],
   "source": [
    "print(\"K-Means\")\n",
    "for i in ['A-T-N-', 'A-T+N+', 'A-T-N+', 'A+T+N-', 'A+T-N-', 'A+T-N+', 'A+T+N+']:\n",
    "    print(i, len(clustering_result_km[i].index), list(clustering_result_km[i].index))\n",
    "    \n",
    "print(\"GMM\")\n",
    "for i in ['A-T-N-', 'A-T+N+', 'A-T-N+', 'A+T+N-', 'A+T-N-', 'A+T-N+', 'A+T+N+']:\n",
    "    print(i, len(clustering_result_gmm[i].index), list(clustering_result_gmm[i].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A-T-N-', 'A+T-N-', 'A+T+N+', 'A-T+N+', 'A+T+N-', 'A-T-N+', 'A+T-N+'])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_result_km.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['A-T-N-', 'A+T-N-', 'A+T+N+', 'A-T+N+', 'A+T+N-', 'A+T-N+', 'A-T-N+'])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_result_gmm.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADNI</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDSD</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARWIBO</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NACC</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>JADNI</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PharmaCog</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1  2  3  4  5\n",
       "ADNI       3  2  0  1  0  2\n",
       "EDSD       2  4  0  1  1  0\n",
       "ARWIBO     2  4  2  3  0  3\n",
       "NACC       9  4  6  2  5  1\n",
       "JADNI      0  3  1  0  0  1\n",
       "PharmaCog  0  1  0  0  1  3"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustering_result_gmm['A+T-N+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in clustering_result_gmm:\n",
    "    clustering_result_gmm[i].to_csv(f\"../results/clustering/gmm/{i}_gmm.csv\")\n",
    "    clustering_result_km[i].to_csv(f\"../results/clustering/k_means/{i}_km.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cramers' V interpretation based on degrees of freedom\n",
    "#### Degrees of freedom is calculated --> min(row-1, column-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramers_df = pd.DataFrame(index=list(range(1,8)), columns=['s', 'm', 'l'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "cramers_df.iloc[0] = [0.1, 0.3, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cramers_df.iloc[0]['m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cramers_df.iloc[1:].index:\n",
    "    \n",
    "    for col in cramers_df.columns:\n",
    "        \n",
    "        cramers_df.loc[i, col] = round(cramers_df.iloc[0][col] / math.sqrt(i), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s</th>\n",
       "      <th>m</th>\n",
       "      <th>l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.045</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.041</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.038</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       s      m      l\n",
       "1    0.1    0.3    0.5\n",
       "2  0.071  0.212  0.354\n",
       "3  0.058  0.173  0.289\n",
       "4   0.05   0.15   0.25\n",
       "5  0.045  0.134  0.224\n",
       "6  0.041  0.122  0.204\n",
       "7  0.038  0.113  0.189"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cramers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
